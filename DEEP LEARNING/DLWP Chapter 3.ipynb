{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "# print(reverse_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000): #10k cols\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop' , loss = \"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 7s 467us/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.7067 - val_acc: 0.8632\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.7345 - val_acc: 0.8619\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 5s 325us/step - loss: 0.0041 - acc: 0.9993 - val_loss: 0.7680 - val_acc: 0.8629\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 5s 315us/step - loss: 0.0017 - acc: 0.9999 - val_loss: 0.8041 - val_acc: 0.8580\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 5s 357us/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.8546 - val_acc: 0.8548\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.8520\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.8821 - val_acc: 0.8597\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 5s 323us/step - loss: 5.7269e-04 - acc: 1.0000 - val_loss: 1.0052 - val_acc: 0.8472\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 5s 321us/step - loss: 4.4671e-04 - acc: 1.0000 - val_loss: 0.9836 - val_acc: 0.8601\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.9863 - val_acc: 0.8579\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 5s 309us/step - loss: 1.9171e-04 - acc: 1.0000 - val_loss: 0.9981 - val_acc: 0.8578\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 5s 342us/step - loss: 1.6230e-04 - acc: 1.0000 - val_loss: 1.0208 - val_acc: 0.8574\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 5s 329us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 1.0507 - val_acc: 0.8580\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 6s 432us/step - loss: 9.7811e-05 - acc: 1.0000 - val_loss: 1.0588 - val_acc: 0.8575\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 5s 338us/step - loss: 8.4128e-05 - acc: 1.0000 - val_loss: 1.0748 - val_acc: 0.8559\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 5s 346us/step - loss: 6.9161e-05 - acc: 1.0000 - val_loss: 1.1182 - val_acc: 0.8552\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 4s 295us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 1.1371 - val_acc: 0.8555\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 4s 300us/step - loss: 3.8675e-05 - acc: 1.0000 - val_loss: 1.1450 - val_acc: 0.8563\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 4s 298us/step - loss: 3.2408e-05 - acc: 1.0000 - val_loss: 1.1581 - val_acc: 0.8550\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 4s 300us/step - loss: 2.6670e-05 - acc: 1.0000 - val_loss: 1.1825 - val_acc: 0.8539\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=512,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-5ca0ad85def9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_loss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training and validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     return gca().plot(\n\u001b[0;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2795\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (20,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(['acc']) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "plt.plot(epochs, [\"accuracy\"], 'bo', label='Training acc')\n",
    "plt.plot(epochs, [\"val_acc\"], 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 24s 954us/step - loss: 0.4614 - acc: 0.8198\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 9s 371us/step - loss: 0.2645 - acc: 0.9065\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 9s 342us/step - loss: 0.2040 - acc: 0.9276\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 208us/step - loss: 0.1703 - acc: 0.9395\n",
      "25000/25000 [==============================] - 48s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2426354 ],\n",
       "       [0.9996636 ],\n",
       "       [0.9233819 ],\n",
       "       ...,\n",
       "       [0.12763548],\n",
       "       [0.06513578],\n",
       "       [0.6993808 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
